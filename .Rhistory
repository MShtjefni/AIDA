}
#GAMMA DISTRIBUTION
if ("gamma" %in% distributionList)
{
print ("fitting gamma...")
fit.gamma<-fitdist(sample,"gamma",method = c("mle"),lower=0)
fit.gamma$estimate
fit.gamma$aic
stats <- replicate(nSims, {
r <- rgamma(n = length(sample), shape = fit.gamma$estimate[1] , rate = fit.gamma$estimate[2]  )
as.numeric(ks.test(r, "pgamma", shape = fit.gamma$estimate[1] , rate = fit.gamma$estimate[2])$statistic
)
})
ks <- ks.test(sample,"pgamma",shape = fit.gamma$estimate[1] , rate = fit.gamma$estimate[2])
ad <- ad.test(sample,"pgamma",shape = fit.gamma$estimate[1] , rate = fit.gamma$estimate[2])
if(nSims) {
fit <- logspline(stats)
D <- 1 - plogspline(ks$statistic, fit)
Ds["gamma"]<-D
}
fits["gamma"]<-list(fit.gamma)
kstests["gamma"]<-list(ks)
adtests["gamma"]<-list(ad)
}
#BETA
if ("beta" %in% distributionList)
{
print ("fitting beta...")
betaSample<-sample/(max(sample)+.1)
fit.beta<-fitdist(betaSample, "beta")
fit.beta$estimate
fit.beta$aic
stats <- replicate(nSims, {
r <- rbeta(n = length(sample), shape1 = fit.beta$estimate[1] , shape2 = fit.beta$estimate[2])
as.numeric(ks.test(r, "pbeta", shape1 = fit.beta$estimate[1] , shape2 = fit.beta$estimate[2])$statistic
)
})
ks <- ks.test(sample,"pbeta",shape1 = fit.beta$estimate[1] , shape2 = fit.beta$estimate[2])
ad <- ad.test(sample,"pbeta",shape1 = fit.beta$estimate[1] , shape2 = fit.beta$estimate[2])
if(nSims) {
fit <- logspline(stats)
D <- 1 - plogspline(ks$statistic, fit)
Ds["beta"]<-D
}
fits["beta"]<-list(fit.beta)
kstests["beta"]<-list(ks)
adtests["beta"]<-list(ad)
}
#WEIBULL
if ("weibull" %in% distributionList)
{
print ("fitting weibull...")
fit.weibull <- fitdist(sample, "weibull")
stats <- replicate(nSims, {
r <- rweibull(n = length(sample)
, shape= fit.weibull$estimate["shape"]
, scale = fit.weibull$estimate["scale"]
)
as.numeric(ks.test(r
, "pweibull"
, shape= fit.weibull$estimate["shape"]
, scale = fit.weibull$estimate["scale"])$statistic
)
})
ks <- ks.test(sample, "pweibull", shape= fit.weibull$estimate["shape"],scale = fit.weibull$estimate["scale"])
ad <- ad.test(sample, "pweibull", shape= fit.weibull$estimate["shape"],scale = fit.weibull$estimate["scale"])
if(nSims) {
fit <- logspline(stats)
D <- 1 - plogspline(ks$statistic, fit)
Ds["weibull"]<-D
}
fits["weibull"]<-list(fit.weibull)
kstests["weibull"]<-list(ks)
adtests["weibull"]<-list(ad)
}
#EXPONENTIAL
if ("exp" %in% distributionList)
{
print ("fitting exp...")
fit.exp<-fitdist(sample,"exp",method = c("mle"),lower=0.01)
stats <- replicate(nSims, {
r <- rexp(n = length(sample), rate = fit.exp$estimate[1]  )
as.numeric(ks.test(r, "pexp", rate = fit.exp$estimate[1])$statistic
)
})
ks <- ks.test(sample,"pexp",rate = fit.exp$estimate[1] )
ad <- ad.test(sample,"pexp",rate = fit.exp$estimate[1] )
if(nSims) {
fit <- logspline(stats)
D <- 1 - plogspline(ks$statistic, fit)
Ds["exp"]<-D
}
fits["exp"]<-list(fit.exp)
kstests["exp"]<-list(ks)
}
#GEOMETRIC
if ("geom" %in% distributionList & all(sample==floor(sample)))
{
print ("fitting geom...")
fit.geom<-fitdist(sample,"geom",method = c("mle"))
stats <- replicate(nSims, {
r <- rgeom(n = length(sample), prob = fit.geom$estimate[1]  )
as.numeric(ks.test(r, "pgeom", prob = fit.geom$estimate[1])$statistic
)
})
ks <- ks.test(sample,"pgeom",prob = fit.geom$estimate[1] )
ad <- ad.test(sample,"pgeom",prob = fit.geom$estimate[1] )
if(nSims) {
fit <- logspline(stats)
D <- 1- plogspline(ks$statistic, fit)
Ds["geom"]<-D
}
fits["geom"]<-list(fit.geom)
kstests["geom"]<-list(ks)
adtests["geom"]<-list(ad)
}
#LOG LOGISTIC
if ("llogis" %in% distributionList)
{
print ("fitting Log logis...")
#parametetrs must be positive
fit.llogis<- fitdist(sample ,"llogis", start = list(shape = 1))
stats <- replicate(nSims, {
r <- rllogis(n = length(sample), shape = fit.llogis$estimate[1]  )
as.numeric(ks.test(r, "pllogis",  shape = fit.llogis$estimate[1])$statistic
)
})
ks <- ks.test(sample,"pllogis", shape = fit.llogis$estimate[1] )
ad <- ad.test(sample,"pllogis", shape = fit.llogis$estimate[1] )
if(nSims) {
fit <- logspline(stats)
D <- 1- plogspline(ks$statistic, fit)
Ds["llogis"]<-D
}
fits["llogis"]<-list(fit.llogis)
kstests["llogis"]<-list(ks)
adtests["llogis"]<-list(ad)
}
#POWERLAW FOR CONTINUOUS ATTRIBUTE
if ("pareto" %in% distributionList)
{
print ("fitting Pareto...")
fit.pareto <- fitdist(sample,"pareto",lower = c(0, 0), start = list(scale = min(sample), shape = 1))
ks.test(sample,"ppareto", scale=fit.pareto$estimate[1] , shape = fit.pareto$estimate[2])
stats <- replicate(nSims, {
r <- rpareto(n = length(sample), shape = fit.pareto$estimate[1]  )
as.numeric(ks.test(r, "ppareto", scale=fit.pareto$estimate[1] , shape = fit.pareto$estimate[2])$statistic
)
})
ks <- ks.test(sample,"ppareto", scale=fit.pareto$estimate[1] , shape = fit.pareto$estimate[2])
ad <- ad.test(sample,"ppareto", scale=fit.pareto$estimate[1] , shape = fit.pareto$estimate[2])
if(nSims) {
fit <- logspline(stats)
D <- 1- plogspline(ks$statistic, fit)
Ds["pareto"]<-D
}
fits["pareto"]<-list(fit.pareto)
kstests["pareto"]<-list(ks)
adtests["pareto"]<-list(ad)
}
# LAPLACE
if ("laplace" %in% distributionList) {
print ("fitting laplace...")
fit.laplace <-fitdist(sample, "laplace",method = c("mle"), start=list(location=1, scale=0.001))
stats <- replicate(nSims, {
r <- rlaplace(n = length(sample), location = fit.laplace$estimate["location"], scale = fit.laplace$estimate["scale"])
as.numeric(ks.test(r, "plaplace", location = fit.laplace$estimate["location"], scale = fit.laplace$estimate["scale"])$statistic
)
})
ks<-ks.test(sample, "plaplace", location = fit.laplace$estimate["location"], scale = fit.laplace$estimate["scale"])
ad<-ad.test(sample, "plaplace", location = fit.laplace$estimate["location"], scale = fit.laplace$estimate["scale"])
if(nSims) {
fit <- logspline(stats)
D<-1 - plogspline(ks$statistic, fit)
Ds["laplace"]<-D
}
fits["laplace"]<-list(fit.laplace)
kstests["laplace"]<-list(ks)
adtests["laplace"]<-list(ad)
}
#CAUCHY
if ("cauchy" %in% distributionList) {
print ("fitting cauchy...")
fit.cauchy <-fitdist(sample, "cauchy",method = c("mle"))
stats <- replicate(nSims, {
r <- rcauchy(n = length(sample), fit.cauchy$estimate[1], fit.cauchy$estimate[2])
as.numeric(ks.test(r, "pcauchy", fit.cauchy$estimate[1], fit.cauchy$estimate[2])$statistic
)
})
ks<-ks.test(sample, "pcauchy", fit.cauchy$estimate[1], fit.cauchy$estimate[2])
ad<-ad.test(sample, "pcauchy", fit.cauchy$estimate[1], fit.cauchy$estimate[2])
if(nSims) {
fit <- logspline(stats)
D<-1 - plogspline(ks$statistic, fit)
Ds["cauchy"]<-D
}
#boot <- bootdist(fit.norm, bootmethod = "param", niter = 1000, ncpus=6) #uses parametric bootsrap to generate
# 1000 samples and compute their parameters according to the given distribution
#fit.norm$CI<-boot$CI[,-1] # returns the 95% bootstrap CIs for all parameters
fits["cauchy"]<-list(fit.cauchy)
kstests["cauchy"]<-list(ks)
adtests["cauchy"]<-list(ad)
}
#LOGIS
if ("logis" %in% distributionList) {
print ("fitting logis...")
fit.logis <-  fitdist(sample, distr="logis", method="mle")
stats <- replicate(nSims, {
r <- rcauchy(n = length(sample), fit.logis$estimate[1], fit.logis$estimate[2])
as.numeric(ks.test(r, "plogis", fit.logis$estimate[1], fit.logis$estimate[2])$statistic
)
})
ks<-ks.test(sample, "plogis", fit.logis$estimate[1], fit.logis$estimate[2])
ad<-ad.test(sample, "plogis", fit.logis$estimate[1], fit.logis$estimate[2])
if(nSims) {
fit <- logspline(stats)
D<-1 - plogspline(ks$statistic, fit)
Ds["logis"]<-D
}
#boot <- bootdist(fit.norm, bootmethod = "param", niter = 1000, ncpus=6) #uses parametric bootsrap to generate
# 1000 samples and compute their parameters according to the given distribution
#fit.norm$CI<-boot$CI[,-1] # returns the 95% bootstrap CIs for all parameters
fits["logis"]<-list(fit.logis)
kstests["logis"]<-list(ks)
adtests["logis"]<-list(ad)
}
### SAVING RESULTS OF SAMPLES USED AND FIT RESULTS INTO A DATASTRUCTURE
if ("beta" %in% distributionList)
gof<-list(gofstat(fits[- which(names(fits)=="beta")]))
else
gof<-list(gofstat(fits))
return (list("sample"=sample, "fits"=fits,"ks"= kstests,"ad" = adtests, "D" = Ds, "gof"=gof))
}
getSortedPValue<-function(resultSet, testColumn='ks') {
pValues<-c()
for (distribution in resultSet[[testColumn]]) {
pValues<-append(pValues,distribution$p.value)
}
names(pValues)<-names(resultSet[[testColumn]])
return (sort(pValues, decreasing = T))
}
getSortedGof<-function(resultSet, measureColumn='aic') {
gof<-sort(resultSet$gof[[1]][[measureColumn]])
#names(pValues)<-names(resultSet[[testColumn]])
return (gof)
}
getMaxSampleSize<-function(samples, pValue=.05, colName='R') {
### RETURNS THE LARGEST SAMPLE SIZE HAVING AT LEAST ONE FITTED DISTRIBUTION WITH P-VALUE>=pValue(IN INPUT)
if (colName=='R')
l<-seq(1, length(samples),2)
else
l<-seq(2, length(samples),2)
for (i in l) {
pV<-getSortedPValue(samples[[i]])
if (max(pV)>=pValue)
s<-i
}
if(exists("s"))
return (names(samples)[s])
return (NULL)
}
### extract samples(of R and E if ER=T, of Growth if growth=T) of distinct sample sizes and fits them by using the distinct distributions defined
sampleAndTest <-function(data, ER=T, growth=F) {
#data is a data structure(eg: list, dataframe) that must contain R and E columns
samples <- results <- list()
if(growth)
if (! "Growth" %in% colnames(data))
print ("Growth is not actually present in data. Calculating it.") + data<-getGrowth(data)
for(i in c(100, 200, 300, 500, 750, 1000, 1500, 2000, 3000, 5000, 10000, 20000, 40000, 80000, 150000, 350000, 700000) ) {
if (ER && i<=min(nrow(subset(data, data$R>=0)), nrow(subset(data, data$E>=0)))) {
print (paste("testing R and E distribution on", toString(i), "elements."))
sample<-sample_n(subset(data, R>=0, E>=0), i)
sampleR<-sample$R+.1
sampleE<-sample$E+1
results[paste(toString(i), "R")]<-list(fitDistributions(sampleR))
results[paste(toString(i), "E")]<-list(fitDistributions(sampleE))
}
if (growth && i<=nrow(subset(data, !is.na(Growth)))) {
sampleG<-sample(subset(data$Growth, !is.na(data$Growth)), i)
results[paste(toString(i), "G")]<-list(fitDistributions(sampleG, nSims = 200, distributionList = c("cauchy", "laplace", "logis")))
}
}
return (results)
}
aidaLarge<-sampleAndTest(subset(aida, Size=="Large"))
aidaLarge<-sampleAndTest(subset(aida, Size=="Large"))
aidaLarge<-sampleAndTest(subset(aida, Size=="Large"))
### EDIT varName TO INSPECT OTHER RESULTS: EG aidaS, aida7, etc. ###
varName="mediaS"
tryCatch(
samples<-eval(parse(text=varName)),
error = function(e) {
load(paste(wdir, "files/", varName, ".RData", sep=""))
samples<<-eval(parse(text=varName))
}
)
pValues<-aicS<-bicS<-list()
for (sample in samples) {
pv<-getSortedPValue(sample)
pValues<-append(pValues,list(pv))
aic<-getSortedGof(sample,measureColumn = 'aic')
aicS<-append(aicS,list(aic))
bic<-getSortedGof(sample,measureColumn = 'bic')
bicS<-append(bicS,list(bic)) }
names(pValues)<-names(aicS)<-names(bicS)<-names(samples)
## EDIT SAMPLE VAR TO HAVE STATISTICS OF ANOTHER SAMPLE ##
distributionColors<-list("My sample"="red", "norm"="brown","llogis"="blue", "lnorm"="yellow","pareto"="aquamarine4","exp"="black","weibull"="blueviolet","gamma"="green", "laplace"="blue", "cauchy"="yellow", "logis"="green")
sample<-samples$`200 E`
xlab = 'Revenue'
x<-sample$sample
fits<-sample$fits
hist(x, prob=T, breaks="fd", xlim = c(min(x)-.1*abs(min(x)), max(x)+.1*abs(max(x))), col="red", main="Empirical small growth Rate Distribution")
makeCurves<-function(distribList, curveType="d",estimatedDistr=fits, mySample=NULL, colors=distributionColors, reduce=0) {
#distribList is the list of distributions you want to plot
#curveType is "d" if you want to plot a density function, "p" if you want to plot an ecdf(probability)
#estimatedDistr is a list of fitted distributions (by fitdist function)
legends<-vector(mode = "character")
distribList<-rev(distribList)
if(!is.null(mySample)) {
if(curveType=="d") {
d<-density(mySample)
x1 <- min(which(d$x >= min(d$x)))
x2 <- max(which(d$x <= max(d$x)))
plot(d, cex=0.5, lwd=2, col="red", xlab=xlab, main = paste(xlab, "Fits"), xlim = c(min(mySample), max(mySample)-(abs(max(mySample)))*reduce))
#with(d, polygon(x=c(x[c(x1,x1:x2,x2)]), y= c(0, y[x1:x2], 0), col="grey69"))
}
else if(curveType=="p")
plot(ecdf(mySample),lwd=2, col="red", xlab=xlab, main = paste(xlab, "Fits"))
legends<-append(legends,"My sample")
}
for (i in (1:length(distribList))) {
currDistr<-distribList[i]
if(endsWith(names(distribList)[i], "mle-norm") | "norm" == names(distribList)[i]) {
curve(do.call(paste(curveType, "norm",sep=""), list(x, estimatedDistr$norm$estimate[1], estimatedDistr$norm$estimate[2])), add=T,col = colors[["norm"]], lwd=2)
legends<-append(legends,"norm")
}
else if(endsWith(names(distribList)[i], "lnorm") | "lnorm" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "lnorm",sep=""), list(x, estimatedDistr$lnorm$estimate[1], estimatedDistr$lnorm$estimate[2])), add=T,col = distributionColors$lnorm, lwd=2)
legends<-append(legends,"lnorm")
}
else if(endsWith(names(distribList)[i], "gamma") | "gamma" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "gamma",sep=""), list(x, estimatedDistr$gamma$estimate[1], estimatedDistr$gamma$estimate[2])), add=T,col = distributionColors$gamma, lwd=2)
legends<-append(legends,"gamma")
}
else if(endsWith(names(distribList)[i], "weibull") | "weibull" %in% names(distribList[i])) {
curve(do.call(paste(curveType, "weibull",sep=""), list(x, estimatedDistr$weibull$estimate[1], estimatedDistr$weibull$estimate[2])), add=T,col = distributionColors$weibull, lwd=2)
legends<-append(legends,"weibull")
}
else if(endsWith(names(distribList)[i], "exp") | "exp" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "exp",sep=""), list(x, estimatedDistr$exp$estimate[1])), add=T,col = distributionColors$exp, lwd=2)
legends<-append(legends,"exp")
}
else if(endsWith(names(distribList)[i], "llogis") | "llogis" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "llogis",sep=""), list(x, estimatedDistr$llogis$estimate[1])), add=T,col = distributionColors$llogis, lwd=2)
legends<-append(legends,"llogis")
}
else if(endsWith(names(distribList)[i], "pareto") | "pareto" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "pareto",sep=""), list(x,  estimatedDistr$pareto$estimate[1] , estimatedDistr$pareto$estimate[2])), add=T,col = distributionColors$pareto , lwd=2)
legends<-append(legends,"pareto")
}
else if(endsWith(names(distribList)[i], "laplace") | "laplace" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "laplace",sep=""), list(x, estimatedDistr$laplace$estimate[1], estimatedDistr$laplace$estimate[2])), add=T,col = distributionColors$laplace, lwd=2)
legends<-append(legends,"laplace")
}
else if(endsWith(names(distribList)[i], "cauchy") | "cauchy" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "cauchy",sep=""), list(x, estimatedDistr$cauchy$estimate[1], estimatedDistr$cauchy$estimate[2])), add=T,col = distributionColors$cauchy, lwd=2)
legends<-append(legends,"cauchy")
}
else if(endsWith(names(distribList)[i], "mle-logis") | "logis" %in% names(distribList)[i]) {
curve(do.call(paste(curveType, "logis",sep=""), list(x, estimatedDistr$logis$estimate[1], estimatedDistr$logis$estimate[2])), add=T,col = distributionColors$logis, lwd=2)
legends<-append(legends,"logis")
}
}
legend("topright", legend=legends,
col=as.character(distributionColors[legends]), lty=1, cex=.8)
}
makeCurves(getSortedGof(sample)[1:3], mySample = x)
makeCurves(getSortedGof(sample)[1:3], mySample = subset(x,x>10))
#makeCurves(getSortedPValue(sample)[1:3])
#BETA SAMPLE (VALUES BETWEEN 0 AND 1)
x2<-x/(max(x)+.1)
hist(x2, prob=T, breaks="fd", xlab="growth_random rate", col="grey", main="Empirical small growth Rate Distribution")
curve(dbeta(x, fits$beta$estimate[1], fits$beta$estimate[2]), add=T,col = "red", lwd=2)
### QQPLOTS
y <- rlnorm(length(x), fits$lnorm$estimate[1], fits$lnorm$estimate[2])
qqplot(y, x, xlab="Theoretical Quantiles", ylab = "Empirical Quantiles")
qqline(rlnorm(length(x), fits$lnorm$estimate[1], fits$lnorm$estimate[2]), col = 2,lwd=2,lty=2, distribution = qlnorm)
#CDF
makeCurves(getSortedGof(sample)[1:3], mySample = x , curveType = "p")
# For fitdistr objects:
boot <- bootdist(fits$pareto, bootmethod = "param", niter = 1000, ncpus = 6) #uses parametric bootsrap to generate
# 1000 samples and compute their parameters according to the given distribution
boot$CI[,-1] # returns the 95% bootstrap CIs for all parameters
#CONFIDENCE INTERVALS FOR PARETO PARAMETERS
myStat <- function(mySample, column) {
print("boot...")
fitdist(mySample[column], "pareto", lower = c(0, 0),
start = list(scale = min(mySample[column]), shape = 1))$estimate}
samples1<-boots<-list()
par(mfrow=c(1,2))
#PLOT CONFIDENCE INTERVALS FOR XMINS AND ALPHAS FOR EACH FIRMS SIZE
for(size in c("Small","Medium","Large")) {
str1<-paste("xmins",size,sep="")
str2<-paste("alphas",size,sep="")
CIx<-plotConfidInterv(data = eval(parse(text=str1)), myValue = eval(parse(text=str1))[[1]])
CIalpha<-plotConfidInterv(data = eval(parse(text=str1)), myValue = eval(parse(text=str1))[[1]])
plot_grid(CIx,CIalpha)
}
CIx
CIalpha
#PLOT CONFIDENCE INTERVALS FOR XMINS AND ALPHAS FOR EACH FIRMS SIZE
for(size in c("Small","Medium","Large")) {
str1<-paste("xmins",size,sep="")
str2<-paste("alphas",size,sep="")
CIx<-plotConfidInterv(data = eval(parse(text=str1)), myValue = eval(parse(text=str1))[[1]])
CIalpha<-plotConfidInterv(data = eval(parse(text=str2)), myValue = eval(parse(text=str1))[[1]])
plot_grid(CIx,CIalpha)
}
CIx
CIalpha
par(mfrow=c(1,2))
#PLOT CONFIDENCE INTERVALS FOR XMINS AND ALPHAS FOR EACH FIRMS SIZE
for(size in c("Small","Medium","Large")) {
str1<-paste("xmins",size,sep="")
str2<-paste("alphas",size,sep="")
CIx<-plotConfidInterv(data = eval(parse(text=str1)), myValue = eval(parse(text=str1))[[1]])
CIalpha<-plotConfidInterv(data = eval(parse(text=str2)), myValue = eval(parse(text=str2))[[1]])
plot_grid(CIx,CIalpha)
}
par(mfrow=c(1,2))
CIalpha
CIx
### BY SETTING XMAX 1-2-3, WE GET 100 BOOTSTRAPPED SAMPLES HAVING XMIN=1 AND ALPHA RANGING BETWEEN 1.6 AND 1.9(approximately).
### THEN, FOR SOME YEARS WE GET  P-VALUES SUFFICIENTLY HIGH(0.4-0.6) (2011-2015). FOR OTHER YEARS(2007, 2009 e.g.) WE GET P-VALUES ALWAYS 0!
### BY PLOTTING, WE CAN SEE THAT FOR SOME YEARS(2013-2015) IT SEEMS REASONABLE, BUT SOMETIMES WE GET P-VALUE 0 EVEN IF WE HAVE SHAPES THAT ARE LIKELY TO BE PARETIAN!
smp<-samplesSize$Small
x<-smp$dat
smp
View(smp)
par(mfrow=c(1,3))
#PLOT TO SEE HOW ALPHAS AND XMINS ARE DISTRIBUTED OVER SMALL, MEDIUM AND LARGE
for(size in c("Small","Medium","Large")) {
str1<-paste("xmins",size,sep="")
str2<-paste("alphas",size,sep="")
plot(eval(parse(text=str1)), eval(parse(text=str2)), main=size, xlab="xmins", ylab="alphas")
}
#CHECK FOR SOME GOOD SAMPLE IN TERMS OF P-VALUE BY KS-TEST...
p=0
i<-1
while(p<.02) {
mySample<-samplesSize[['Medium']][[i]]
x<-mySample$dat
xmin<-mySample$xmin
alpha<-mySample$pars
ks<-ks.test(x,"ppareto", scale=xmin, shape = alpha)
p<-ks$p.value
ks2<-ks.test(subset(x,x>=xmin),"ppareto", scale=xmin, shape = alpha)
p2<-ks2$p.value
print(paste("p:",p, ", xmin:", xmin, "p2:", p2))
i<-i+1
plot(density(x), main=toString(i))
curve(dpareto(x,scale = xmin, shape = alpha), add = T, col='blue', main=toString(i))
}
#CHECK FOR SOME GOOD SAMPLE IN TERMS OF P-VALUE BY KS-TEST...
p=0
i<-1
size<-'Medium'
while(p<.02) {
mySample<-samplesSize[[size]][[i]]
x<-mySample$dat
xmin<-mySample$xmin
alpha<-mySample$pars
ks<-ks.test(x,"ppareto", scale=xmin, shape = alpha)
p<-ks$p.value
ks2<-ks.test(subset(x,x>=xmin),"ppareto", scale=xmin, shape = alpha)
p2<-ks2$p.value
print(paste("p:",p, ", xmin:", xmin, "p2:", p2))
i<-i+1
plot(density(x), main=toString(i))
curve(dpareto(x,scale = xmin, shape = alpha), add = T, col='blue', main=toString(i))
}
largeSample<-samplesSize[['Large']][[1]]
a<-plotConfidInterv(xminsLarge, largeSample$xmin, xtitle = "bootstrapped xmins")
b<-plotConfidInterv(alphasLarge, largeSample$pars, xtitle = "bootstrapped alphas")
plot_grid(a,b)
bt<-bootstrap_p(mySample)
bt<-bootstrap_p(mySample, threads = 6)
### BY SETTING XMAX 1-2-3, WE GET 100 BOOTSTRAPPED SAMPLES HAVING XMIN=1 AND ALPHA RANGING BETWEEN 1.6 AND 1.9(approximately).
### THEN, FOR SOME YEARS WE GET  P-VALUES SUFFICIENTLY HIGH(0.4-0.6) (2011-2015). FOR OTHER YEARS(2007, 2009 e.g.) WE GET P-VALUES ALWAYS 0!
### BY PLOTTING, WE CAN SEE THAT FOR SOME YEARS(2013-2015) IT SEEMS REASONABLE, BUT SOMETIMES WE GET P-VALUE 0 EVEN IF WE HAVE SHAPES THAT ARE LIKELY TO BE PARETIAN!
smp<-samplesSize$Small[[1]]
x<-smp$dat
kurtosis(x) ###VERY HIGH, THAT'S WHY WE HAVE VERY "HEAVY" TAILS IN COMPARISON OF NORMAL DISTRIBUTION (kurtosis=3)
xmin<-smp$xmin
alpha<-smp$pars
plot(density(x))
plot(density(x))
### BY SETTING XMAX 1-2-3, WE GET 100 BOOTSTRAPPED SAMPLES HAVING XMIN=1 AND ALPHA RANGING BETWEEN 1.6 AND 1.9(approximately).
### THEN, FOR SOME YEARS WE GET  P-VALUES SUFFICIENTLY HIGH(0.4-0.6) (2011-2015). FOR OTHER YEARS(2007, 2009 e.g.) WE GET P-VALUES ALWAYS 0!
### BY PLOTTING, WE CAN SEE THAT FOR SOME YEARS(2013-2015) IT SEEMS REASONABLE, BUT SOMETIMES WE GET P-VALUE 0 EVEN IF WE HAVE SHAPES THAT ARE LIKELY TO BE PARETIAN!
smp<-samplesSize$Small[[1]]
x<-smp$dat
kurtosis(x) ###VERY HIGH, THAT'S WHY WE HAVE VERY "HEAVY" TAILS IN COMPARISON OF NORMAL DISTRIBUTION (kurtosis=3)
xmin<-smp$xmin
alpha<-smp$pars
plotDensity(x, xtitle = "Employees", mainTitle = "Small firms")
curve(dpareto(x, scale = xmin, shape = alpha), add = T, col="red", lwd=2)
x<-subset(x,x>=xmin)
plot(density(x))
curve(dpareto(x, scale = xmin, shape = alpha), add = T, col="red", lwd=2)
load("~/UNIVERSITÀ/SMD/PROGETTO/files/plE_By_Years.RData")
View(samplesE2)
